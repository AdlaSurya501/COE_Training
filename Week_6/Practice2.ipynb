{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4f6e56",
   "metadata": {},
   "source": [
    "**What is Feature Engineering?**\n",
    " \n",
    "            Feature engineering is the process of creating new features or modifying existing ones to improve the performance of machine learning models. It involves techniques like feature extraction, transformation, encoding, and scaling to make data more useful for predictions.\n",
    " \n",
    "**Why Do We Need Feature Engineering?**\n",
    " \n",
    "1.**Improves Model Performance** – Good features help models make better predictions.\n",
    " \n",
    "2.**Reduces Overfitting** – Helps eliminate noise and irrelevant data.\n",
    " \n",
    "3.**Handles Missing Data** – Creates meaningful replacements for missing values.\n",
    " \n",
    "4.**Enables Better Interpretability** – Makes features more understandable and useful.\n",
    "\n",
    "5.**Reduces Dimensionality** – Helps remove unnecessary data points, making the model efficient.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cdf4b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TransactionDate  DayOfWeek  Hour  IsWeekend\n",
      "0 2025-02-05 14:30:00          2    14          0\n",
      "1 2025-02-06 18:45:00          3    18          0\n"
     ]
    }
   ],
   "source": [
    "#Extract Date & Time Features\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "#Sample dataset\n",
    "df = pd.DataFrame({'TransactionDate': pd.to_datetime(['2025-02-05 14:30:00','2025-02-06 18:45:00'])})\n",
    "                   \n",
    "#Extract date-related features\n",
    "df['DayOfWeek'] = df['TransactionDate'].dt.dayofweek\n",
    "df['Hour'] = df['TransactionDate'].dt.hour\n",
    "df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)  # 5 and 6 represent Saturday and Sunday\n",
    "\n",
    "print(df)\n",
    "# Why? Helps capture behavioral T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47bde5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  AvgTransactionAmount\n",
      "0     101                 600.0\n",
      "1     102                 350.0\n",
      "2     103                1000.0\n"
     ]
    }
   ],
   "source": [
    "#Aggregated Features\n",
    "#Find Average transaction amount per user:\n",
    "df_transactions = pd.DataFrame({\n",
    "    'UserID': [101,102,101,103,102],\n",
    "    'TransactionAmount': [500,300,700,1000,400]\n",
    "})\n",
    "\n",
    "df_user_avg = df_transactions.groupby('UserID')['TransactionAmount'].mean().reset_index()\n",
    "df_user_avg.rename(columns={'TransactionAmount': 'AvgTransactionAmount'},inplace=True)\n",
    "print(df_user_avg)\n",
    "#Why? Identifies high-value customers and spending patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8769132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   productcategory_Clothing  productcategory_Electronics  \\\n",
      "0                       0.0                          1.0   \n",
      "1                       1.0                          0.0   \n",
      "2                       1.0                          0.0   \n",
      "3                       0.0                          0.0   \n",
      "\n",
      "   productcategory_grocery  \n",
      "0                      0.0  \n",
      "1                      0.0  \n",
      "2                      0.0  \n",
      "3                      1.0  \n"
     ]
    }
   ],
   "source": [
    "#Encoding Categorical Variables\n",
    "#Convert ProductCategory (Electronics, Clothing) into numerical form:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df=pd.DataFrame({'productcategory':['Electronics','Clothing','Clothing','grocery']})\n",
    "encoder=OneHotEncoder(sparse_output=False)\n",
    "encoded_features=encoder.fit_transform(df[['productcategory']])\n",
    "df_encoded=pd.DataFrame(encoded_features,columns=encoder.get_feature_names_out())\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c54cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Transformationn for Skewed Data\n",
    "#If TransactionAmount has outliers, apply log transformation:\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'TransactionAmount': [100,200,5000,10000,20000]})\n",
    "df['LogTransactionAmount'] = np.log1p(df['TransactionAmount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be5fc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount  NormalizedTransactionAmount  \\\n",
      "0                100              4.615121                     0.000000   \n",
      "1                200              5.303305                     0.005025   \n",
      "2               5000              8.517393                     0.246231   \n",
      "3              10000              9.210440                     0.497487   \n",
      "4              20000              9.903538                     1.000000   \n",
      "\n",
      "   StandardizedTransactionAmount  \n",
      "0                      -0.937070  \n",
      "1                      -0.923606  \n",
      "2                      -0.277351  \n",
      "3                       0.395831  \n",
      "4                       1.742196  \n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['NormalizedTransactionAmount'] = scaler.fit_transform(df[['TransactionAmount']])\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "df['StandardizedTransactionAmount'] = standard_scaler.fit_transform(df[['TransactionAmount']])\n",
    "\n",
    "print(df)\n",
    "\n",
    "#Why? Ensure all features have the same scale, preventing bias in ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4193f",
   "metadata": {},
   "source": [
    "**Final Summary of Feature Engineering & Imbalanced Data Handling**\n",
    " \n",
    "Feature Extraction : Extract new insights from raw data (e.g., Hour, DayOfWeek)\n",
    " \n",
    "Aggregated Features : Calculate meaningful statistics (e.g., AvgTransactionAmountPerUser)\n",
    " \n",
    "Encoding : Convert categorical variables into numerical (One-Hot Encoding)\n",
    " \n",
    "Log Transformation : Reduce skewness in data distribution\n",
    " \n",
    "Feature Scaling : Normalize numerical features for better model performance\n",
    " \n",
    "Downsampling: Reduce the size of the majority class\n",
    " \n",
    "Upsampling : Increase the size of the minority class\n",
    " \n",
    "SMOTE(Synthetic Minority Over-sampling Technique) : Generate synthetic samples for the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4aa27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
